{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e60ef88-f74a-4535-a61b-6108772542e0",
   "metadata": {},
   "source": [
    "<font size=\"+3\"><strong>4.2. Predicting Damage with Logistic Regression</strong></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b7d53-42ca-48be-a131-3453a1338857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from category_encoders import OneHotEncoder\n",
    "from IPython.display import VimeoVideo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae9845-8a73-465f-aea7-9768bccdce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414074\", h=\"d441543f18\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89792f1-bdc7-4846-b118-4f4399c5a08b",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1081f1b-0e9f-4a14-ac46-ba2301b23ab7",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c26181-db22-488d-ab03-fc76e00412c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(db_path):\n",
    "    # Connect to database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # Construct query\n",
    "    query = \"\"\"\n",
    "        SELECT distinct(i.building_id) AS b_id,\n",
    "           s.*,\n",
    "           d.damage_grade\n",
    "        FROM id_map AS i\n",
    "        JOIN building_structure AS s ON i.building_id = s.building_id\n",
    "        JOIN building_damage AS d ON i.building_id = d.building_id\n",
    "        WHERE district_id = 4\n",
    "    \"\"\"\n",
    "\n",
    "    # Read query results into DataFrame\n",
    "    df = .\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac25fd-341a-4f73-982c-27f5d0eb00a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414541\", h=\"dfe22afdfb\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce879a-e68f-431b-9248-9d975d2650d3",
   "metadata": {},
   "source": [
    "**Task 4.2.1:** Complete the `wrangle` function above so that the it returns the results of `query` as a DataFrame. Be sure that the index column is set to `\"b_id\"`. Also, the path to the SQLite database is `\"../nepal.sqlite\"`.\n",
    "\n",
    "- [<span id='technique'>Read SQL query into a DataFrame using <span id='tool'>pandas</span></span>.](../%40textbook/10-databases-sql.ipynb#Using-pandas-with-SQL-Databases)\n",
    "- [<span id='technique'>Write a function in <span id='tool'>Python</span></span>.](../%40textbook/02-python-advanced.ipynb#Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a529fc-0e26-48b7-aac6-99b6eaa78698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe1d53-28e1-4a0d-bf02-e9ea3e256e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your work\n",
    "assert df.shape[0] == 70836, f\"`df` should have 70,836 rows, not {df.shape[0]}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f29296-dd21-4313-8dfe-003e314fd285",
   "metadata": {},
   "source": [
    "There seem to be several features in `df` with information about the condition of a property after the earthquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1447c19-b711-4160-8346-f832548c7cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414560\", h=\"ad4bba19ed\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8063973-6854-4301-9d96-2cf5ab715d6f",
   "metadata": {},
   "source": [
    "**Task 4.2.2:** Add to your wrangle function so that these features are dropped from the DataFrame. Don't forget to rerun all the cells above. \n",
    "\n",
    "- [<span id='technique'>Drop a column from a DataFrame using <span id='tool'>pandas</span></span>.](../%40textbook/03-pandas-getting-started.ipynb#Dropping-Columns)\n",
    "- [<span id='technique'>Subset a DataFrame's columns based on column names in <span id='tool'>pandas</span></span>.](../%40textbook/04-pandas-advanced.ipynb#Subset-a-DataFrame-by-Selecting-One-or-More-Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0fb999-2922-40b9-a089-2cf9f696f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504254f-f094-4934-8433-cccda372f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your work\n",
    "assert (\n",
    "    df.filter(regex=\"post_eq\").shape[1] == 0\n",
    "), \"`df` still has leaky features. Try again!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4780a879-483f-4c34-bc94-2d7facbbe541",
   "metadata": {},
   "source": [
    "We want to build a **binary classification** model, but our current target `\"damage_grade\"` has more than two categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae1b0c-a4f8-4a73-a486-22dae569bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414603\", h=\"12b3d2f23e\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acbb2b6-be6e-4cad-b78e-780de0071c52",
   "metadata": {},
   "source": [
    "**Task 4.2.3:** Add to your wrangle function so that it creates a new target column `\"severe_damage\"`. For buildings where the `\"damage_grade\"` is Grade 4 or above, `\"severe_damage\"` should be `1`. For all other buildings, `\"severe_damage\"` should be `0`. Don't forget to drop `\"damage_grade\"` to avoid leakage, and rerun all the cells above.\n",
    "\n",
    "- [<span id='technique'>Access a substring in a Series using <span id='tool'>pandas</span></span>.](../%40textbook/03-pandas-getting-started.ipynb#Access-a-substring-in-a-Series)\n",
    "- [<span id='technique'>Drop a column from a DataFrame using <span id='tool'>pandas</span></span>.](../%40textbook/03-pandas-getting-started.ipynb#Dropping-Columns)\n",
    "- [<span id='technique'>Recast a column as a different data type in <span id='tool'>pandas</span></span>.](../%40textbook/03-pandas-getting-started.ipynb#Recasting-Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be38c4-2c57-4bd4-8cba-ab8f1623ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"severe_damage\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08cee97-7a8f-4cc0-80d4-a974f327f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your work\n",
    "assert (\n",
    "    \"damage_grade\" not in df.columns\n",
    "), \"Your DataFrame should not include the `'damage_grade'` column.\"\n",
    "assert (\n",
    "    \"severe_damage\" in df.columns\n",
    "), \"Your DataFrame is missing the `'severe_damage'` column.\"\n",
    "assert (\n",
    "    df[\"severe_damage\"].value_counts().shape[0] == 2\n",
    "), f\"The `'damage_grade'` column should have only two unique values, not {df['severe_damage'].value_counts().shape[0]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b72f7-0e18-4bc0-8e3a-57173f20c775",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5166d21-b3ef-4d6d-9c2e-13de228009ed",
   "metadata": {},
   "source": [
    "Since our model will be a type of linear model, we need to make sure there's no issue with multicollinearity in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ad56c-58ba-4357-ad9d-47d073d9706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414636\", h=\"d34256b4e3\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0529e84c-3043-48e6-bac1-e292fca82eaa",
   "metadata": {},
   "source": [
    "**Task 4.2.4:** Plot a correlation heatmap of the remaining numerical features in `df`. Since `\"severe_damage\"` will be your target, you don't need to include it in your heatmap. \n",
    "\n",
    "- [What's a <span id='term'>correlation coefficient</span>?](../%40textbook/05-pandas-summary-statistics.ipynb#Correlations)\n",
    "- [What's a <span id='term'>heatmap</span>?](../%40textbook/09-visualization-seaborn.ipynb#Correlation-Heatmaps)\n",
    "- [<span id='technique'>Create a correlation matrix in <span id='tool'>pandas</span></span>.](../%40textbook/07-visualization-pandas.ipynb#Correlation-Matrices)\n",
    "- [<span id='technique'>Create a heatmap in <span id='tool'>seaborn</span></span>.](../%40textbook/09-visualization-seaborn.ipynb#Correlation-Heatmaps)\n",
    "\n",
    "Do you see any features that you need to drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91926e6-d776-48b7-86da-74f9751420bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "correlation = ...\n",
    "# Plot heatmap of `correlation`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af1c85-670f-4f76-a593-bfd31e8b95b2",
   "metadata": {},
   "source": [
    "**Task 4.2.5:** Change `wrangle` function so that it drops the `\"count_floors_pre_eq\"` column. Don't forget to rerun all the cells above. \n",
    "\n",
    "- [<span id='technique'>Drop a column from a DataFrame using <span id='tool'>pandas</span></span>.](../%40textbook/03-pandas-getting-started.ipynb#Dropping-Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa34c3-05d0-4c0e-908e-45e74336b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your work\n",
    "assert (\n",
    "    \"count_floors_pre_eq\" not in df.columns\n",
    "), \"Did you drop the `'count_floors_pre_eq'` column?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabbf0ab-7f0d-4970-9f2e-8e3637667220",
   "metadata": {},
   "source": [
    "Before we build our model, let's see if we can identify any obvious differences between houses that were severely damaged in the earthquake (`\"severe_damage\"==1`) those that were not (`\"severe_damage\"==0`). Let's start with a numerical feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cfbb95-533e-4336-a34d-c930dd405636",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414667\", h=\"f39c2c21bc\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86449de0-fc89-44bd-8871-f0b54a005753",
   "metadata": {},
   "source": [
    "**Task 4.2.6:** Use seaborn to create a boxplot that shows the distributions of the `\"height_ft_pre_eq\"` column for both groups in the `\"severe_damage\"` column. Remember to label your axes. \n",
    "\n",
    "- [What's a <span id='term'>boxplot</span>?](../%40textbook/06-visualization-matplotlib.ipynb#Boxplots)\n",
    "- [<span id='technique'>Create a boxplot using <span id='tool'>Matplotlib</span></span>.](../%40textbook/06-visualization-matplotlib.ipynb#Boxplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e56e5-c959-4884-967b-734a1f6b77f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplot\n",
    "\n",
    "# Label axes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ed2b2-81a3-4e65-adc5-8d2e49664902",
   "metadata": {},
   "source": [
    "Before we move on to the many categorical features in this dataset, it's a good idea to see the balance between our two classes. What percentage were severely damaged, what percentage were not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c5d457-bf29-4820-a64d-d459f5d33cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414684\", h=\"81295d5bdb\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a81528-deb5-4f3d-9f63-3e813b9033ab",
   "metadata": {},
   "source": [
    "**Task 4.2.7:** Create a bar chart of the value counts for the `\"severe_damage\"` column. You want to calculate the relative frequencies of the classes, not the raw count, so be sure to set the `normalize` argument to `True`.\n",
    "\n",
    "- [What's a <span id='term'>bar chart</span>?](../%40textbook/06-visualization-matplotlib.ipynb#Bar-Charts)\n",
    "- [What's a <span id='technique'>majority class</span>?](../%40textbook/14-ml-classification.ipynb#Majority-and-Minority-Classes)\n",
    "- [What's a <span id='technique'>minority class</span>?](../%40textbook/14-ml-classification.ipynb#Majority-and-Minority-Classes)\n",
    "- [Aggregate data in a Series using `value_counts` in pandas.](../%40textbook/04-pandas-advanced.ipynb#Working-with-value_counts-in-a-Series)\n",
    "- [<span id='technique'>Create a bar chart using <span id='tool'>pandas</span></span>.](../%40textbook/07-visualization-pandas.ipynb#Bar-Charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a67db-8cf3-4070-b23d-01a91dbdceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot value counts of `\"severe_damage\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e97d2-526d-4a0e-8515-c0dcb376fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414697\", h=\"ee2d4f28c6\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110128d4-d927-47a0-a3b0-ee5f2ac66129",
   "metadata": {},
   "source": [
    "**Task 4.2.8:** Create two variables, `majority_class_prop` and `minority_class_prop`, to store the normalized value counts for the two classes in `df[\"severe_damage\"]`. \n",
    "\n",
    "- [Aggregate data in a Series using `value_counts` in pandas.](../%40textbook/04-pandas-advanced.ipynb#Working-with-value_counts-in-a-Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffca415-1416-445d-9ba4-4b78a7993606",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class_prop, minority_class_prop = ...\n",
    "print(majority_class_prop, minority_class_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b3197e-9a0a-48f4-bcaf-e296903ef563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your work\n",
    "assert (\n",
    "    majority_class_prop < 1\n",
    "), \"`majority_class_prop` should be a floating point number between 0 and 1.\"\n",
    "assert (\n",
    "    minority_class_prop < 1\n",
    "), \"`minority_class_prop` should be a floating point number between 0 and 1.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346cd49-dd3c-4c02-a4d7-3a94881c633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414718\", h=\"6a1e0c1e53\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88eec5e-6109-4d80-a749-1a69d7d3ab4f",
   "metadata": {},
   "source": [
    "**Task 4.2.9:** Are buildings with certain foundation types more likely to suffer severe damage? Create a pivot table of `df` where the index is `\"foundation_type\"` and the values come from the `\"severe_damage\"` column, aggregated by the mean.\n",
    "\n",
    "- [What's a <span id='term'>pivot table</span>?](../%40textbook/04-pandas-advanced.ipynb#Pivot-Tables)\n",
    "- [<span id='technique'>Reshape a DataFrame based on column values in <span id='tool'>pandas</span></span>.](../%40textbook/04-pandas-advanced.ipynb#Reshape-a-DataFrame-based-on-column-values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f7bf0-2f9f-4c06-90fd-1865ebf50c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table\n",
    "foundation_pivot = ...\n",
    "foundation_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7daea-8831-41d8-b529-d421f48dfc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414734\", h=\"46de83f96e\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518ed69b-bf02-46bd-a9c9-97611f8df39f",
   "metadata": {},
   "source": [
    "**Task 4.2.10:** How do the proportions in `foundation_pivot` compare to the proportions for our majority and minority classes? Plot `foundation_pivot` as horizontal bar chart, adding vertical lines at the values for `majority_class_prop` and `minority_class_prop`.\n",
    "\n",
    "- [What's a <span id='term'>bar chart</span>?](../%40textbook/07-visualization-pandas.ipynb#Bar-Charts)\n",
    "- [<span id='technique'>Add a vertical or horizontal line across a plot using <span id='term'>Matplotlib</span></span>.](../%40textbook/06-visualization-matplotlib.ipynb#Add-a-vertical-or-horizontal-line-across-a-plot)\n",
    "- [<span id='technique'>Create a bar chart using <span id='tool'>pandas</span></span>.](../%40textbook/07-visualization-pandas.ipynb#Bar-Charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a57b45-1d64-4acb-886c-5382ffbcc9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart of `foundation_pivot`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9023dc16-7f70-4d51-8313-525d8eb4c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414748\", h=\"8549a0f89c\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b8f43-bae6-45a3-a08e-8686ef7da5db",
   "metadata": {},
   "source": [
    "**Task 4.2.11:** Combine the [`select_dtypes`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html) and [`nunique`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nunique.html) methods to see if there are any high- or low-cardinality categorical features in the dataset. \n",
    "\n",
    "- [What are <span id='term'>high- and low-cardinality features</span>?](../%40textbook/14-ml-classification.ipynb#High-cardinality-Features)\n",
    "- [<span id='technique'>Determine the unique values in a column using <span id='tool'>pandas</span></span>.](../%40textbook/03-pandas-getting-started.ipynb#Determine-the-unique-values-in-a-column) \n",
    "- [<span id='technique'>Subset a DataFrame's columns based on the column data types in <span id='tool'>pandas</span></span>.](../%40textbook/04-pandas-advanced.ipynb#Subset-the-Columns-of-a-DataFrame-Based-on-Data-Types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e39138-98f4-4279-b8bd-b5ab243ab1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for high- and low-cardinality categorical features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3806583-4ccf-45bb-9f30-02a95e707345",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01991064-e0a6-4b8b-a22f-c6cc3a820ee7",
   "metadata": {},
   "source": [
    "**Task 4.2.12:** Create your feature matrix `X` and target vector `y`. Your target is `\"severe_damage\"`. \n",
    "\n",
    "- [What's a <span id='term'>feature matrix</span>?](../%40textbook/15-ml-regression.ipynb#Linear-Regression)\n",
    "- [What's a <span id='term'>target vector</span>?](../%40textbook/15-ml-regression.ipynb#Linear-Regression)\n",
    "- [<span id='technique'>Subset a DataFrame by selecting one or more columns in <span id='tool'>pandas</span></span>.](../%40textbook/04-pandas-advanced.ipynb#Subset-a-DataFrame-by-Selecting-One-or-More-Columns) \n",
    "- [<span id='technique'>Select a Series from a DataFrame in <span id='tool'>pandas</span></span>.](../%40textbook/04-pandas-advanced.ipynb#Combine-multiple-categories-in-a-Series) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7fef15-0678-4c4c-a2f2-84ee12cc50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"severe_damage\"\n",
    "X = ...\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d65285-4832-4502-818b-40074ea02fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414769\", h=\"1bfddf07b2\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f90dce4-5880-4fff-acfa-9099e2c8141a",
   "metadata": {},
   "source": [
    "**Task 4.2.13:** Divide your data (`X` and `y`) into training and test sets using a randomized train-test split. Your test set should be 20% of your total data. And don't forget to set a `random_state` for reproducibility. \n",
    "\n",
    "- [<span id='technique'>Perform a randomized train-test split using <span id='tool'>scikit-learn</span></span>.](../%40textbook/14-ml-classification.ipynb#Randomized-Train-Test-split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471fa464-bb90-4a52-af2f-73266e53a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0145e4-d0bb-4ba6-8b63-27da32fe4910",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p><b>Frequent Question:</b> Why do we set the random state to <code>42</code>?</p>\n",
    "    <p><b>Answer:</b> The truth is you can pick any integer when setting a random state. The number you choose doesn't affect the results of your project; it just makes sure that your work is reproducible so that others can verify it. However, lots of people choose <code>42</code> because it appears in a well-known work of science fiction called <a href='https://en.wikipedia.org/wiki/42_(number)#The_Hitchhiker's_Guide_to_the_Galaxy'>The Hitchhiker's Guide to the Galaxy</a>. In short, it's an inside joke. ðŸ˜‰</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c5f58-1635-4b63-bfc0-102d63139859",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafdd5ca-bde6-4cf0-a8ce-94286b4494cb",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90073acd-0f79-4338-a358-4b7ac661b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414807\", h=\"c997c58720\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a15aa-2f2f-40de-a606-602eb9281fde",
   "metadata": {},
   "source": [
    "**Task 4.2.14:** Calculate the baseline accuracy score for your model.\n",
    "\n",
    "- [What's <span id='tool'>accuracy score</span>?](../%40textbook/14-ml-classification.ipynb#Calculating-Accuracy-Score)\n",
    "- [Aggregate data in a Series using `value_counts` in pandas.](../%40textbook/04-pandas-advanced.ipynb#Working-with-value_counts-in-a-Series)<span style='color: transparent; font-size:1%'>WQU WorldQuant University Applied Data Science Lab QQQQ</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65edada-56fe-454a-a38d-bbbb0ddb2f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_baseline = ...\n",
    "print(\"Baseline Accuracy:\", round(acc_baseline, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4098e3e-72dd-4426-847b-7bdc33bcf15b",
   "metadata": {},
   "source": [
    "## Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61da634-dff0-4f0c-b815-c415effb0e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414835\", h=\"1d8673223e\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89c7494-dac1-4cdf-bf32-87eed972b0ed",
   "metadata": {},
   "source": [
    "**Task 4.2.15:** Create a pipeline named `model` that contains a `OneHotEncoder` transformer and a `LogisticRegression` predictor. Be sure you set the `use_cat_names` argument for your transformer to `True`. Then fit it to the training data. \n",
    "\n",
    "- [What's <span id='term'>logistic regression</span>?](../%40textbook/14-ml-classification.ipynb#Logistic-Regression)\n",
    "- [What's <span id='term'>one-hot encoding</span>?](../%40textbook/13-ml-data-pre-processing-and-production.ipynb#One-Hot-Encoding)\n",
    "- [<span id='technique'>Create a pipeline in <span id='tool'>scikit-learn</span></span>.](../%40textbook/13-ml-data-pre-processing-and-production.ipynb#Creating-a-Pipeline-in-scikit-learn)\n",
    "- [<span id='technique'>Fit a model to training data in <span id='tool'>scikit-learn</span></span>.](../%40textbook/15-ml-regression.ipynb#Fitting-a-Model-to-Training-Data)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> If you get a <code>ConvergenceWarning</code></b> when you fit your model to the training data, don't worry. This can sometimes happen with logistic regression models. Try setting the <code>max_iter</code> argument in your predictor to <code>1000</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7ee88-52a2-4461-9b07-705a9abe6f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = ...\n",
    "# Fit model to training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6ae76-43f4-4c3b-936a-f0c794c03108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your work\n",
    "assert isinstance(\n",
    "    model, Pipeline\n",
    "), f\"`model` should be a Pipeline, not type {type(model)}.\"\n",
    "assert isinstance(\n",
    "    model[0], OneHotEncoder\n",
    "), f\"The first step in your Pipeline should be a OneHotEncoder, not type {type(model[0])}.\"\n",
    "assert isinstance(\n",
    "    model[-1], LogisticRegression\n",
    "), f\"The last step in your Pipeline should be LogisticRegression, not type {type(model[-1])}.\"\n",
    "check_is_fitted(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19634c38-c36f-48b3-9d82-8a89e33b6eb4",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17ddd7-0b35-4eea-af1f-5a15bff3a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414885\", h=\"f35ff0e23e\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22932c04-a053-499c-bd08-66de0d532d0f",
   "metadata": {},
   "source": [
    "**Task 4.2.16:** Calculate the training and test accuracy scores for your models. \n",
    "\n",
    "- [<span id='technique'>Calculate the accuracy score for a model in <span id='term'>scikit-learn</span></span>.](../%40textbook/14-ml-classification.ipynb#Calculating-Accuracy-Score)\n",
    "- [<span id='technique'>Generate predictions using a trained model in <span id='term'>scikit-learn</span></span>.](../%40textbook/15-ml-regression.ipynb#Generating-Predictions-Using-a-Trained-Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c25ba4-de2d-44cc-89fe-7240cc3a0c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = ...\n",
    "acc_test = ...\n",
    "\n",
    "print(\"Training Accuracy:\", round(acc_train, 2))\n",
    "print(\"Test Accuracy:\", round(acc_test, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aefbd7-2d94-4f4e-bfc6-b0ac4ef3fed9",
   "metadata": {},
   "source": [
    "# Communicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d17c2ce-fc0d-42b8-aeb9-28aba9e4f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414902\", h=\"f9bdbe9e75\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a110d0-ee26-4338-a3da-2a3138d5f9c4",
   "metadata": {},
   "source": [
    "**Task 4.2.17:** Instead of using the `predict` method with your model, try `predict_proba` with your training data. How does the `predict_proba` output differ than that of `predict`? What does it represent?\n",
    "\n",
    "- [<span id='technique'>Generate probability estimates using a trained model in <span id='tool'>scikit-learn</span></span>.](../%40textbook/14-ml-classification.ipynb#Probability-Estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b91ad42-a1d9-49d5-be9f-d442991c7c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_proba = ...\n",
    "print(y_train_pred_proba[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044787eb-ef3a-498d-9548-2c8ffdcacbb2",
   "metadata": {},
   "source": [
    "**Task 4.2.18:** Extract the feature names and importances from your `model`.\n",
    "\n",
    "- [<span id='technique'>Access an object in a pipeline in <span id='tool'>scikit-learn</span></span>.](../%40textbook/13-ml-data-pre-processing-and-production.ipynb#Accessing-an-Object-in-a-Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca314b-5fa3-44d8-bc62-15dc165859a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ...\n",
    "importances = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4cb96d-6f1a-45b2-91b9-b11a2ed36d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414916\", h=\"c0540604cd\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aedeb5d-617e-4da1-8828-664467856cfc",
   "metadata": {},
   "source": [
    "**Task 4.2.19:** Create a pandas Series named `odds_ratios`, where the index is `features` and the values are your the exponential of the `importances`. How does `odds_ratios` for this model look different from the other linear models we made in projects 2 and 3?\n",
    "\n",
    "- [<span id='technique'>Create a Series in <span id='tool'>pandas</span></span>.](../%40textbook/04-pandas-advanced.ipynb#Subset-a-DataFrame-by-Selecting-One-or-More-Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d29e3-ce90-4df2-822b-4f83e3ecfcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_ratios = ...\n",
    "odds_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d7fbd9-226e-4d9a-8910-7271b2d51c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414943\", h=\"56eb74d93e\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165549de-8b20-4360-9f3f-fff29f525efc",
   "metadata": {},
   "source": [
    "**Task 4.2.20:** Create a horizontal bar chart with the five largest coefficients from `odds_ratios`. Be sure to label your x-axis `\"Odds Ratio\"`.\n",
    "\n",
    "- [What's a <span id='term'>bar chart</span>?](../%40textbook/06-visualization-matplotlib.ipynb#Bar-Charts)\n",
    "- [<span id='technique'>Create a bar chart using <span id='tool'>Matplotlib</span></span>.](../%40textbook/06-visualization-matplotlib.ipynb#Bar-Charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d9f874-ddf8-402d-abb3-d537fe7d81a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal bar chart, five largest coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ff145-74e6-40ac-93a1-575644719606",
   "metadata": {},
   "outputs": [],
   "source": [
    "VimeoVideo(\"665414964\", h=\"a61b881450\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab1506-5334-48d2-8863-53e9dee87777",
   "metadata": {},
   "source": [
    "**Task 4.2.21:** Create a horizontal bar chart with the five smallest coefficients from `odds_ratios`. Be sure to label your x-axis `\"Odds Ratio\"`.\n",
    "\n",
    "- [What's a <span id='term'>bar chart</span>?](../%40textbook/06-visualization-matplotlib.ipynb#Bar-Charts)\n",
    "- [<span id='technique'>Create a bar chart using <span id='tool'>Matplotlib</span></span>.](../%40textbook/06-visualization-matplotlib.ipynb#Bar-Charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47fcfc-aed1-41c7-8a9b-7b758b7185e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal bar chart, five smallest coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc3d24",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "Copyright 2023 WorldQuant University. This\n",
    "content is licensed solely for personal use. Redistribution or\n",
    "publication of this material is strictly prohibited.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
